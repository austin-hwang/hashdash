{"jobtitle":"Data Engineer","company":"Intelliswift Software","city":"San Mateo","state":"CA","country":"US","language":"en","formattedLocation":"San Mateo, CA","source":"Monster","date":"Tue, 01 Aug 2017 01:05:00 GMT","snippet":"Expertise with Java or Scala. Behavioural Tracking and Analytics:. Integrate and productionize machine learning and statistical models into real-time services,...","url":"http://www.indeed.com/viewjob?jk=43d12f4894d9da1f","onmousedown":"indeed_clk(this,'6534');","latitude":37.53846,"longitude":-122.3022,"jobkey":"43d12f4894d9da1f","sponsored":false,"expired":false,"indeedApply":false,"formattedLocationFull":"San Mateo, CA 94403","formattedRelativeTime":"2 days ago","stations":"","jtr_description":"While applying please mention \" DD_DataEng \" in the subject line...\n\nJob Description:\n\nYou will collaborate closely with data scientists and cross functional business units to develop data pipelines, infrastructure and applications in the following areas:\nBehavioural Tracking and Analytics: core infrastructure for monitoring and deriving insights from site traffic.\nProduct Recommendation and Personalization: providing personalized product recommendations and user experience for sports fans in e-commerce sites as well as on emails.\nInventory optimization: forecasting demand and optimizing the quantity and location of inventory.\nProduct Finding: deploying key components of online-search, including ranking models, spell correction, query expansion and query understanding.\n\nJob Responsibilities:\n\nDevelop robust and scalable data infrastructure components for monitoring and tracking, messaging, real-time streaming and batch data processing use cases.\nIntegrate and productionize machine learning and statistical models into real-time services, as well as BI & Visualization layers.\nWork closely with data scientists to assist on feature engineering, model training frameworks, and model deployments at scale.\nProvide engineering leadership in the design and architecture of data infrastructure and applications.\n\nJob Requirements:\n\n2+ years of experience with big data processing in Spark, Hadoop, Hive and/or Redshift.\nExpertise with Java or Scala.\nExperience designing and developing data models, integrating data from multiple sources, building ETL pipelines, and supporting all aspects of the software development lifecycle. At this time, this role is not\n\nopen to recent grads.\n\nStrong SQL programming knowledge and experience.\nExperience developing web services, API integrations, and data exchanges with third parties is preferred.\nAbility to communicate quantitative analysis and analytical findings in a clear, precise, and actionable manner.\nEnergetic, enthusiastic, detail-oriented, and passionate about producing high-quality analytics deliverables.\nKnowledge of basic statistical analysis and machine learning a plus.\nMS/BS in Computer Science, MIS, Mathematics, Physics or other quantitative field or relevant work experience.\n\n","jtr_source":"indeed"}